{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import utility as util\n",
    "import network as net\n",
    "\n",
    "# data var\n",
    "xLength             = 64\n",
    "device              = 'cuda:0'\n",
    "version             = '_1'\n",
    "\n",
    "dataSet             = np.load('simul_Data.npz')\n",
    "dataSimulFID        = dataSet['FID']\n",
    "dataSimulConc       = dataSet['Conc']\n",
    "dataSimulintactFID  = dataSet['FID_intact']\n",
    "intactBasis         = dataSet['Basis']\n",
    "\n",
    "# train var\n",
    "trainNum            = 256\n",
    "validNum            = 10\n",
    "minibatchSize       = 128\n",
    "epochNum            = 3\n",
    "minibatchSize_eval  = 10\n",
    "\n",
    "learningRate        = 0.001\n",
    "hiddenDim           = 300\n",
    "layerNum            = 1\n",
    "teacherForce        = 0.5\n",
    "\n",
    "######################################################################################################################################\n",
    "# train data func\n",
    "def getDataloader(xLen,dataX,dataY,batchSize,shuf):\n",
    "    class RNN_Dataset(torch.utils.data.Dataset):\n",
    "        def __init__(self):\n",
    "            self.x_data = torch.FloatTensor(util.Normalize(dataX[:,:xLen,:],dataX[:,:xLen,:])).to(device)\n",
    "            self.y_data = torch.FloatTensor(util.Normalize(dataY[:,:xLen,:],dataX[:,:xLen,:])).to(device)\n",
    "        def __len__(self):\n",
    "            return len(self.x_data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            x = self.x_data[idx]\n",
    "            y = self.y_data[idx]\n",
    "            return x, y\n",
    "\n",
    "    Train_dataset    = RNN_Dataset()\n",
    "    if shuf == 'shufT':\n",
    "        RNN_dataloader = torch.utils.data.DataLoader(Train_dataset, batch_size = batchSize, shuffle = True)\n",
    "    elif shuf == 'shufF':\n",
    "        RNN_dataloader = torch.utils.data.DataLoader(Train_dataset, batch_size = batchSize, shuffle = False)\n",
    "    return RNN_dataloader\n",
    "######################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################\n",
    "# train func\n",
    "def getRNN(xLen,LearnRate,hiddenNum,layerNum):\n",
    "    # data\n",
    "    dataloader_train = getDataloader(xLen,dataSimulFID[:trainNum,:,:],dataSimulintactFID[:trainNum,:,:],minibatchSize,'shufT')\n",
    "    # model\n",
    "    encoder          = net.cRNN_encoder(hiddenNum, layerNum)\n",
    "    decoder          = net.cRNN_decoder(hiddenNum, layerNum)\n",
    "    map_first        = net.MappingFirstPoint(xLen)\n",
    "    model            = net.cRNN(encoder, decoder, map_first).to(device)\n",
    "    # train\n",
    "    optimizer        = torch.optim.Adam(model.parameters(), lr=LearnRate)\n",
    "    \n",
    "    for epoch in range(epochNum):\n",
    "        model.train()\n",
    "        for _, samples in enumerate(dataloader_train):\n",
    "            x_train, y_train  = samples\n",
    "            x_predict         = model(x_train, y_train, xLen, teacherForce, device)\n",
    "            cost_train        = torch.nn.MSELoss()\n",
    "            cost              = cost_train(x_predict, y_train)\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(epoch+1,'/',epochNum,\n",
    "                'Train_cost: ',round(cost.item(),6),\n",
    "                'Valid_cost: ',round(evalRNN(xLen,model,dataSimulFID[trainNum:trainNum+validNum,:,:],dataSimulintactFID[trainNum:trainNum+validNum,:,:],minibatchSize_eval).item(),6)\n",
    "                )\n",
    "    return model\n",
    "\n",
    "def evalRNN(xLen,model_eval,data_evalX,data_evalY,batchSize_eval):\n",
    "    dataloader_eval    = getDataloader(xLen,data_evalX,data_evalY,batchSize_eval,'shufF')\n",
    "    model_eval.eval()\n",
    "    with torch.no_grad():\n",
    "        costSum_eval = 0.0\n",
    "        for _, samples in enumerate(dataloader_eval):\n",
    "            x_eval, y_eval = samples\n",
    "            x_predict      = model_eval(x_eval, y_eval, xLen,  0, device)\n",
    "            cost_eval      = torch.nn.MSELoss()\n",
    "            costSum_eval  += cost_eval(x_predict, y_eval)\n",
    "    return costSum_eval/(len(data_evalX)/batchSize_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model   = getRNN(xLength, learningRate, hiddenDim, layerNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalConc(Conc):\n",
    "    # [    0,    1,   2,     3,    4,    5,    6,    7,    8,    9,  10,   11,    12,  13,   14,  15,   16,   17,    18,   19,    20]\n",
    "    # ['Ala','Asp','Cr','GABA','Glc','Gln','Glu','GPC','GSH','Lac','mI','NAA','NAAG','PC','PCr','PE','Tau','Glx','tCho','tCr','tNAA']\n",
    "    TotalConc = np.zeros((len(Conc),21))\n",
    "    TotalConc[:,:17]= Conc[:,:]\n",
    "    TotalConc[:,17] = Conc[:,5] + Conc[:,6]\n",
    "    TotalConc[:,18] = Conc[:,7] + Conc[:,13]\n",
    "    TotalConc[:,19] = Conc[:,14] + Conc[:,2]\n",
    "    TotalConc[:,20] = Conc[:,12] + Conc[:,11]\n",
    "    return TotalConc\n",
    "\n",
    "def getConc(X_intactFID,Y_conc,intactBasis):\n",
    "    X_conc = getTotalConc(np.dot(X_intactFID.real,np.linalg.pinv(intactBasis.real)))\n",
    "    Y_conc = getTotalConc(Y_conc)\n",
    "    MAPE   = np.mean(((100*np.abs(X_conc-Y_conc))/Y_conc),axis=0)\n",
    "    return X_conc, MAPE\n",
    "\n",
    "def getintactFID_RNN(xLen,model_eval,data_evalX,batchSize_eval):\n",
    "    dataloader_eval    = getDataloader(xLen,data_evalX,data_evalX,batchSize_eval,'shufF')\n",
    "    model_eval.eval()\n",
    "    with torch.no_grad():\n",
    "        predFID_eval_normal = torch.Tensor([]).to(device)\n",
    "        for _, samples in enumerate(dataloader_eval):\n",
    "            x_eval, y_eval      = samples\n",
    "            x_predict           = model_eval(x_eval, y_eval, xLen,  0, device)\n",
    "            predFID_eval_normal = torch.cat([predFID_eval_normal,x_predict],0)\n",
    "    preFID_eval = util.returnNormalize(predFID_eval_normal.data.cpu().numpy(),data_evalX[:,:xLen,:])\n",
    "    return preFID_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FID            = dataSimulFID[-10:,:xLength,:]\n",
    "test_Conc           = dataSimulConc[-10:,:]\n",
    "recon_FID           = getintactFID_RNN(xLength,model,test_FID,10)\n",
    "recon_Conc, MAPE    = getConc(recon_FID,test_Conc,intactBasis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_FID[0,:,0])\n",
    "plt.plot(recon_FID[0,:].real)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "693434f7fc6b5ca2f2282639c3347fa1640c6b0d5d07470d49c84b9bb0b3d2aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
